{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9991307,"sourceType":"datasetVersion","datasetId":6149082}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T02:55:29.563180Z","iopub.execute_input":"2024-11-24T02:55:29.563559Z","iopub.status.idle":"2024-11-24T02:55:29.963541Z","shell.execute_reply.started":"2024-11-24T02:55:29.563525Z","shell.execute_reply":"2024-11-24T02:55:29.962614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np  \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport tensorflow.keras.utils as ku  \nfrom wordcloud import WordCloud \nfrom tensorflow.keras.preprocessing.sequence import pad_sequences \nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional \nfrom tensorflow.keras.preprocessing.text import Tokenizer \nfrom tensorflow.keras.models import Sequential \nfrom tensorflow.keras.optimizers import Adam \nfrom tensorflow.keras import regularizers  \nfrom sklearn.model_selection import train_test_split \nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nimport tensorflow as tf \nfrom tensorflow.keras.regularizers import l2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T06:39:42.355060Z","iopub.execute_input":"2024-11-24T06:39:42.355836Z","iopub.status.idle":"2024-11-24T06:39:42.361056Z","shell.execute_reply.started":"2024-11-24T06:39:42.355805Z","shell.execute_reply":"2024-11-24T06:39:42.360239Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"file_path = '/kaggle/input/robert-frost-poems-dataset-cleaned/cleaned_data.csv'\ndata = pd.read_csv(file_path, encoding='ISO-8859-1', header=None)  \n\nnew_header = ['title']  \ndata.columns=new_header\ndata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T02:55:50.315841Z","iopub.execute_input":"2024-11-24T02:55:50.316427Z","iopub.status.idle":"2024-11-24T02:55:50.348646Z","shell.execute_reply.started":"2024-11-24T02:55:50.316388Z","shell.execute_reply":"2024-11-24T02:55:50.347607Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data['title'] = data['title'].apply(lambda x: x.replace(u'\\xa0',u' '))\ndata['title'] = data['title'].apply(lambda x: x.replace('\\u200a',' ')) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T02:55:56.363948Z","iopub.execute_input":"2024-11-24T02:55:56.364791Z","iopub.status.idle":"2024-11-24T02:55:56.371340Z","shell.execute_reply.started":"2024-11-24T02:55:56.364734Z","shell.execute_reply":"2024-11-24T02:55:56.370266Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = Tokenizer(oov_token='<oov>') \ntokenizer.fit_on_texts(data['title'])\ntotal_words = len(tokenizer.word_index) + 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T03:01:30.640766Z","iopub.execute_input":"2024-11-24T03:01:30.641508Z","iopub.status.idle":"2024-11-24T03:01:30.656465Z","shell.execute_reply.started":"2024-11-24T03:01:30.641475Z","shell.execute_reply":"2024-11-24T03:01:30.655605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sentences=data['title'].tolist()\ninput_sequences = []\nfor sentence in sentences:\n    token_list = tokenizer.texts_to_sequences([sentence])[0]\n    \n    \n    for i in range(1, len(token_list)):\n        n_gram_sequence = token_list[:i+1]  \n        input_sequences.append(n_gram_sequence)\n\n\nmax_sequence_len = max(len(seq) for seq in input_sequences)\n\ninput_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\nX, y = input_sequences[:, :-1], input_sequences[:, -1]\n\ny = tf.keras.utils.to_categorical(y, num_classes=total_words) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T03:17:16.150381Z","iopub.execute_input":"2024-11-24T03:17:16.151271Z","iopub.status.idle":"2024-11-24T03:17:16.331827Z","shell.execute_reply.started":"2024-11-24T03:17:16.151237Z","shell.execute_reply":"2024-11-24T03:17:16.331122Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=42) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T05:15:49.606585Z","iopub.execute_input":"2024-11-24T05:15:49.607442Z","iopub.status.idle":"2024-11-24T05:15:49.667220Z","shell.execute_reply.started":"2024-11-24T05:15:49.607405Z","shell.execute_reply":"2024-11-24T05:15:49.666469Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\nmodel.add(Bidirectional(LSTM(150)))\nmodel.add(Dense(total_words, activation='softmax'))\nadam = Adam(learning_rate=0.01)\nmodel.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])  \n\nhistory = model.fit(X_train, y_train, epochs=12, verbose=1, batch_size=16, validation_split=0.2)\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:58:26.989461Z","iopub.execute_input":"2024-11-24T07:58:26.989803Z","iopub.status.idle":"2024-11-24T08:05:00.669060Z","shell.execute_reply.started":"2024-11-24T07:58:26.989772Z","shell.execute_reply":"2024-11-24T08:05:00.668178Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seed_text = \"woods are lovely\"\nnext_words = 25\n  \nfor _ in range(next_words):\n    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n\n    predicted=model.predict(token_list) \n    predicted=np.argmax(predicted,axis=1)\n    output_word = \"\"\n    for word, index in tokenizer.word_index.items():\n        if index == predicted:\n            output_word = word\n            break\n    seed_text += \" \" + output_word\nprint(seed_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:05:24.913780Z","iopub.execute_input":"2024-11-24T08:05:24.914356Z","iopub.status.idle":"2024-11-24T08:05:27.182405Z","shell.execute_reply.started":"2024-11-24T08:05:24.914322Z","shell.execute_reply":"2024-11-24T08:05:27.181529Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def accuracy(X, y, model):  \n    total_samples=X.shape[0]\n    y_pred=model.predict(X)\n    correct_samples=0\n    for i in range(X.shape[0]): \n        y1=np.argmax(y[i])\n        y2=np.argmax(y_pred[i])\n        if (y1==y2): \n            correct_samples+=1\n            \n    return correct_samples/total_samples \n\n\nacc1=accuracy(X_test, y_test, model) \nprint(acc1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:52:02.166455Z","iopub.execute_input":"2024-11-24T08:52:02.166806Z","iopub.status.idle":"2024-11-24T08:52:05.350321Z","shell.execute_reply.started":"2024-11-24T08:52:02.166778Z","shell.execute_reply":"2024-11-24T08:52:05.349596Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_perplexity(model, X_test, y_test):\n    predictions = model.predict(X_test)  \n    \n    cross_entropy_loss = tf.keras.losses.categorical_crossentropy(y_test, predictions)\n    perplexity = np.exp(np.mean(cross_entropy_loss))\n    return perplexity\n\nperplexity = calculate_perplexity(model, X_test, y_test)\nprint(perplexity)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:55:22.814302Z","iopub.execute_input":"2024-11-24T08:55:22.814674Z","iopub.status.idle":"2024-11-24T08:55:26.013991Z","shell.execute_reply.started":"2024-11-24T08:55:22.814642Z","shell.execute_reply":"2024-11-24T08:55:26.013104Z"}},"outputs":[],"execution_count":null}]}